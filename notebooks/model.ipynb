{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22257 entries, 0 to 22256\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   title      22257 non-null  object\n",
      " 1   predictor  22257 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 347.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(r'../data/processed_data/modelo_dataset.parquet')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparar y optimizar datos textuales para el modelo de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uso de memoria: 558.24609375 MB\n",
      "El vectorizador está utilizando 40000 características.\n",
      "Dimensiones reducidas a 400 componentes.\n"
     ]
    }
   ],
   "source": [
    "# Crear el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer(min_df=4, max_df=0.85, ngram_range=(1, 2), max_features=40000, dtype=np.float32)\n",
    "\n",
    "# Transformar la columna 'overview' en una matriz TF-IDF\n",
    "matriz = vectorizer.fit_transform(df['predictor'])\n",
    "\n",
    "# Reductir la dimensionalidad con SVD.\n",
    "svd = TruncatedSVD(n_components=400, random_state=42)\n",
    "matriz_reducida = svd.fit_transform(matriz)\n",
    "\n",
    "# Contar características y uso de memoria\n",
    "num_features = len(vectorizer.vocabulary_)\n",
    "\n",
    "# Monitorearuso de memoria\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / (1024 * 1024)  # Convertir de bytes a MB\n",
    "\n",
    "print(f\"Uso de memoria: {get_memory_usage()} MB\")\n",
    "print(f\"El vectorizador está utilizando {num_features} características.\")\n",
    "print(f\"Dimensiones reducidas a {matriz_reducida.shape[1]} componentes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se implementa una función de recomendación que utiliza la similitud de coseno para encontrar películas similares basándose en la representación vectorial de las descripciones (en este caso, la columna predictor). También se incluye un mecanismo para verificar el uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recomendaciones': ['toy story 2', 'hawaiian vacation', 'toy story 3', 'small fry', 'partysaurus rex']}\n",
      "Uso de memoria: 555.4609375 MB\n"
     ]
    }
   ],
   "source": [
    "def recommendacion(title):\n",
    "    # Encontrar el índice de la película\n",
    "    title = title.lower()\n",
    "    idx = df.index[df['title'] == title].tolist()\n",
    "    if not idx:\n",
    "        return \"Película no encontrada\"\n",
    "    idx = idx[0]\n",
    "    \n",
    "    # Calcular la matriz de similitud del coseno\n",
    "    sim_scores = cosine_similarity(matriz_reducida[idx].reshape(1, -1), matriz_reducida)\n",
    "    \n",
    "    # Obtener y ordenar los puntajes de similitud\n",
    "    sim_scores = list(enumerate(sim_scores[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Obtener las películas más similares\n",
    "    movie_indices = [i[0] for i in sim_scores[1:6]]  # 10 películas más similares\n",
    "    recomendaciones = df['title'].iloc[movie_indices].tolist()\n",
    "    return {\"Recomendaciones\": recomendaciones}\n",
    "\n",
    "# Prueba la función de recomendación\n",
    "print(recommendacion('toy story'))\n",
    "\n",
    "# Monitorear el uso de memoria\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / (1024 * 1024)  # Convertir de bytes a MB\n",
    "\n",
    "print(f\"Uso de memoria: {get_memory_usage()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed_data/matriz_reducida.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '../data/processed_data/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Guardar el modelo TF-IDF y la matriz reducida\n",
    "joblib.dump(vectorizer, os.path.join(directory, 'vectorizer.pkl'))\n",
    "joblib.dump(matriz_reducida, os.path.join(directory, 'matriz_reducida.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vectorizer: 1.34 MB\n",
      "Tamaño de la matriz reducida: 33.96 MB\n"
     ]
    }
   ],
   "source": [
    "# Rutas de los archivos\n",
    "vectorizer_path = '../data/processed_data/vectorizer.pkl'\n",
    "matriz_reducida_path = '../data/processed_data/matriz_reducida.pkl'\n",
    "\n",
    "# Función para obtener el tamaño de un archivo\n",
    "def get_file_size(file_path):\n",
    "    try:\n",
    "        size = os.path.getsize(file_path)  # Obtener el tamaño en bytes\n",
    "        return size / (1024 * 1024)  # Convertir a MB\n",
    "    except FileNotFoundError:\n",
    "        return \"El archivo no existe.\"\n",
    "\n",
    "# Obtener y mostrar el tamaño de los archivos\n",
    "vectorizer_size = get_file_size(vectorizer_path)\n",
    "matriz_reducida_size = get_file_size(matriz_reducida_path)\n",
    "\n",
    "print(f\"Tamaño del vectorizer: {vectorizer_size:.2f} MB\")\n",
    "print(f\"Tamaño de la matriz reducida: {matriz_reducida_size:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyectDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
